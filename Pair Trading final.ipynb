{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b601bca-87d7-40b7-be0f-5cd51af1aec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pair: 1INCH, AAVE\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from scipy.stats import norm, logistic, genextreme\n",
    "from copulas.multivariate import GaussianMultivariate\n",
    "\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import optuna\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from copulas.multivariate import GaussianMultivariate\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "path = r\"C:\\Users\\manan\\Downloads\\Pt 1\\data\\\\DataBETA\"\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "file_data_dict = {}\n",
    "\n",
    "dfl = []\n",
    "for f in csv_files:\n",
    "    x = pd.read_csv(f)\n",
    "    x.index = pd.to_datetime(x['time'])\n",
    "    x = x['close']\n",
    "    dfl.append(x)\n",
    "\n",
    "for idx, file in enumerate(csv_files):\n",
    "    file_name = os.path.basename(file)\n",
    "    file_data_dict[idx] = file_name\n",
    "modified_dict = {}\n",
    "for key, file_name in file_data_dict.items():\n",
    "    new_value = file_name.split('data_')[1].split('-USDT-SWAP.csv')[0]\n",
    "    modified_dict[key] = new_value\n",
    "\n",
    "df_dict = {}\n",
    "for i in range(len(dfl)):\n",
    "    df_dict[i] = pd.DataFrame({modified_dict[i]: dfl[i]})\n",
    "row_col_names = list(modified_dict.values())\n",
    "df = pd.DataFrame(1, index=row_col_names, columns=row_col_names)\n",
    "merged_df = pd.concat(dfl, axis=1)\n",
    "merged_df.columns = [modified_dict[i] for i in range(len(dfl))]\n",
    "merged_df = merged_df.dropna()\n",
    "merged_df = merged_df.iloc[:, :6]\n",
    "\n",
    "# Step 1: Load and prepare returns data\n",
    "returns_df = merged_df.pct_change().dropna()\n",
    "\n",
    "# Step 2: Define helper functions for marginal fitting and copula selection\n",
    "def fit_marginal_distribution(series, dist_type='normal'):\n",
    "    if dist_type == 'normal':\n",
    "        return norm.fit(series)\n",
    "    elif dist_type == 'logistic':\n",
    "        return logistic.fit(series)\n",
    "    elif dist_type == 'genextreme':\n",
    "        return genextreme.fit(series)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported distribution type\")\n",
    "\n",
    "def get_residuals(series, params, dist_type='normal'):\n",
    "    if dist_type == 'normal':\n",
    "        return (series - params[0]) / params[1]\n",
    "    elif dist_type == 'logistic':\n",
    "        location, scale = params\n",
    "        return (series - location) / scale\n",
    "    elif dist_type == 'genextreme':\n",
    "        c, loc, scale = params\n",
    "        return (series - loc) / scale\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported distribution type\")\n",
    "\n",
    "# Step 3: Check cointegration between all pairs\n",
    "cointegrated_pairs = []\n",
    "p_value_threshold = 0.05\n",
    "\n",
    "for (col1, col2) in itertools.combinations(returns_df.columns, 2):\n",
    "    score, p_value, _ = coint(returns_df[col1], returns_df[col2])\n",
    "    if p_value < p_value_threshold:\n",
    "        cointegrated_pairs.append((col1, col2))\n",
    "\n",
    "\n",
    "copula_signals = {}\n",
    "\n",
    "for pair in cointegrated_pairs:\n",
    "    stock1, stock2 = pair\n",
    "    print(f\"Processing pair: {stock1}, {stock2}\")\n",
    "\n",
    "    \n",
    "    params1 = fit_marginal_distribution(returns_df[stock1], dist_type='normal')\n",
    "    params2 = fit_marginal_distribution(returns_df[stock2], dist_type='normal')\n",
    "\n",
    "    \n",
    "    u1 = norm.cdf(get_residuals(returns_df[stock1], params1, dist_type='normal'))\n",
    "    u2 = norm.cdf(get_residuals(returns_df[stock2], params2, dist_type='normal'))\n",
    "\n",
    "    \n",
    "    copula_signals[pair] = []\n",
    "    \n",
    "\n",
    "# Fit copula (Gaussian example)\n",
    "    copula = GaussianMultivariate()  # Use GaussianMultivariate instead of GaussianCopula\n",
    "    copula.fit(pd.DataFrame({'U1': u1, 'U2': u2}))\n",
    "    \n",
    "    # Generate copula-based signals\n",
    "    copula_signals[pair] = []\n",
    "    threshold = 0.975  # Arbitrary threshold; adjust based on strategy requirements\n",
    "    \n",
    "    for i in range(len(u1)):\n",
    "        joint_prob = copula.cumulative_distribution([u1.iloc[i], u2.iloc[i]])\n",
    "        if joint_prob > threshold:\n",
    "            copula_signals[pair].append(('Sell', stock1, stock2))  # Excess positive correlation\n",
    "        elif joint_prob < 1 - threshold:\n",
    "            copula_signals[pair].append(('Buy', stock1, stock2))  # Excess negative correlation\n",
    "        else:\n",
    "            copula_signals[pair].append(('Hold', stock1, stock2))\n",
    "\n",
    "\n",
    "\n",
    "initial_cash = 100000  \n",
    "cash = initial_cash\n",
    "position_size = initial_cash / len(copula_signals) / 2  \n",
    "returns = []\n",
    "\n",
    "for pair, signals in copula_signals.items():\n",
    "    stock1, stock2 = pair\n",
    "    stock1_returns = returns_df[stock1]\n",
    "    stock2_returns = returns_df[stock2]\n",
    "    \n",
    "    for i, (signal, s1, s2) in enumerate(signals):\n",
    "        if signal == 'Buy':\n",
    "            cash += position_size * (stock1_returns.iloc[i] - stock2_returns.iloc[i])\n",
    "        elif signal == 'Sell':\n",
    "            cash += position_size * (stock2_returns.iloc[i] - stock1_returns.iloc[i])\n",
    "\n",
    "    returns.append(cash / initial_cash - 1)\n",
    "\n",
    "total_return = cash / initial_cash - 1\n",
    "print(f\"Total Return from Copula-based Pairs Trading: {total_return * 100:.2f}%\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.cumsum(returns), label=\"Copula-based Strategy\")\n",
    "plt.xlabel(\"Trading Days\")\n",
    "plt.ylabel(\"Cumulative Return\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc3b2383-0ca8-4b68-86e7-2ec0607ba6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa0acf4-6680-4ca5-aa19-a2bd38fbe083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
