{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b601bca-87d7-40b7-be0f-5cd51af1aec3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 82\u001b[0m\n\u001b[0;32m     79\u001b[0m p_value_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (col1, col2) \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mcombinations(returns_df\u001b[38;5;241m.\u001b[39mcolumns, \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m---> 82\u001b[0m     score, p_value, _ \u001b[38;5;241m=\u001b[39m coint(returns_df[col1], returns_df[col2])\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p_value \u001b[38;5;241m<\u001b[39m p_value_threshold:\n\u001b[0;32m     84\u001b[0m         cointegrated_pairs\u001b[38;5;241m.\u001b[39mappend((col1, col2))\n",
      "File \u001b[1;32mD:\\Programs\\Python\\Lib\\site-packages\\statsmodels\\tsa\\stattools.py:1806\u001b[0m, in \u001b[0;36mcoint\u001b[1;34m(y0, y1, trend, method, maxlag, autolag, return_results)\u001b[0m\n\u001b[0;32m   1803\u001b[0m res_co \u001b[38;5;241m=\u001b[39m OLS(y0, xx)\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m   1805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res_co\u001b[38;5;241m.\u001b[39mrsquared \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m SQRTEPS:\n\u001b[1;32m-> 1806\u001b[0m     res_adf \u001b[38;5;241m=\u001b[39m adfuller(\n\u001b[0;32m   1807\u001b[0m         res_co\u001b[38;5;241m.\u001b[39mresid, maxlag\u001b[38;5;241m=\u001b[39mmaxlag, autolag\u001b[38;5;241m=\u001b[39mautolag, regression\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1808\u001b[0m     )\n\u001b[0;32m   1809\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1810\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1811\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my0 and y1 are (almost) perfectly colinear.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1812\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCointegration test is not reliable in this case.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1813\u001b[0m         CollinearityWarning,\n\u001b[0;32m   1814\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1815\u001b[0m     )\n",
      "File \u001b[1;32mD:\\Programs\\Python\\Lib\\site-packages\\statsmodels\\tsa\\stattools.py:326\u001b[0m, in \u001b[0;36madfuller\u001b[1;34m(x, maxlag, regression, autolag, store, regresults)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;66;03m# 1 for level\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;66;03m# search for lag length with smallest information criteria\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;66;03m# Note: use the same number of observations to have comparable IC\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# aic and bic: smaller is better\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m regresults:\n\u001b[1;32m--> 326\u001b[0m     icbest, bestlag \u001b[38;5;241m=\u001b[39m _autolag(\n\u001b[0;32m    327\u001b[0m         OLS, xdshort, fullRHS, startlag, maxlag, autolag\n\u001b[0;32m    328\u001b[0m     )\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     icbest, bestlag, alres \u001b[38;5;241m=\u001b[39m _autolag(\n\u001b[0;32m    331\u001b[0m         OLS,\n\u001b[0;32m    332\u001b[0m         xdshort,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    337\u001b[0m         regresults\u001b[38;5;241m=\u001b[39mregresults,\n\u001b[0;32m    338\u001b[0m     )\n",
      "File \u001b[1;32mD:\\Programs\\Python\\Lib\\site-packages\\statsmodels\\tsa\\stattools.py:133\u001b[0m, in \u001b[0;36m_autolag\u001b[1;34m(mod, endog, exog, startlag, maxlag, method, modargs, fitargs, regresults)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(startlag, startlag \u001b[38;5;241m+\u001b[39m maxlag \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    132\u001b[0m     mod_instance \u001b[38;5;241m=\u001b[39m mod(endog, exog[:, :lag], \u001b[38;5;241m*\u001b[39mmodargs)\n\u001b[1;32m--> 133\u001b[0m     results[lag] \u001b[38;5;241m=\u001b[39m mod_instance\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maic\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    136\u001b[0m     icbest, bestlag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m((v\u001b[38;5;241m.\u001b[39maic, k) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mitems())\n",
      "File \u001b[1;32mD:\\Programs\\Python\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:336\u001b[0m, in \u001b[0;36mRegressionModel.fit\u001b[1;34m(self, method, cov_type, cov_kwds, use_t, **kwargs)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpinv\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpinv_wexog\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    333\u001b[0m             \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalized_cov_params\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    334\u001b[0m             \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m--> 336\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpinv_wexog, singular_values \u001b[38;5;241m=\u001b[39m pinv_extended(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwexog)\n\u001b[0;32m    337\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalized_cov_params \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\n\u001b[0;32m    338\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpinv_wexog, np\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpinv_wexog))\n\u001b[0;32m    340\u001b[0m         \u001b[38;5;66;03m# Cache these singular values for use later.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Programs\\Python\\Lib\\site-packages\\statsmodels\\tools\\tools.py:264\u001b[0m, in \u001b[0;36mpinv_extended\u001b[1;34m(x, rcond)\u001b[0m\n\u001b[0;32m    262\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\n\u001b[0;32m    263\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mconjugate()\n\u001b[1;32m--> 264\u001b[0m u, s, vt \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39msvd(x, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    265\u001b[0m s_orig \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(s)\n\u001b[0;32m    266\u001b[0m m \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mD:\\Programs\\Python\\Lib\\site-packages\\numpy\\linalg\\linalg.py:1681\u001b[0m, in \u001b[0;36msvd\u001b[1;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[0;32m   1678\u001b[0m         gufunc \u001b[38;5;241m=\u001b[39m _umath_linalg\u001b[38;5;241m.\u001b[39msvd_n_s\n\u001b[0;32m   1680\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->DdD\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->ddd\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 1681\u001b[0m u, s, vh \u001b[38;5;241m=\u001b[39m gufunc(a, signature\u001b[38;5;241m=\u001b[39msignature, extobj\u001b[38;5;241m=\u001b[39mextobj)\n\u001b[0;32m   1682\u001b[0m u \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1683\u001b[0m s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mastype(_realType(result_t), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata\n",
    "from statsmodels.api import add_constant\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "from statsmodels.tsa.stattools import coint\n",
    "import numpy as np\n",
    "from copulas.multivariate import GaussianMultivariate\n",
    "from copulas.bivariate import Clayton, Gumbel, Frank\n",
    "from copulas.univariate import StudentTUnivariate\n",
    "from copulas.visualization import scatter_2d\n",
    "import time\n",
    "csv_files = glob.glob(os.path.join(\"*.csv\"))\n",
    "file_data_dict = {}\n",
    "modified_dict = {}\n",
    "dfl = []\n",
    "for idx, file in enumerate(csv_files):\n",
    "    file_name = os.path.basename(file)\n",
    "    instrument_name = file_name.split('data_')[1].split('-USDT-SWAP.csv')[0]\n",
    "    x = pd.read_csv(file, parse_dates=['time'], index_col='time')['close']\n",
    "    dfl.append(x)\n",
    "    modified_dict[idx] = instrument_name\n",
    "\n",
    "merged_df = pd.concat(dfl, axis=1)\n",
    "merged_df.columns = [modified_dict[i] for i in range(len(dfl))]\n",
    "merged_df = merged_df.dropna()\n",
    "\n",
    "cdf_df = merged_df.apply(lambda x: rankdata(x) / len(x), axis=0)\n",
    "\n",
    "train_size = int(len(cdf_df) * 0.6)\n",
    "train_data, test_data = cdf_df.iloc[:train_size], cdf_df.iloc[train_size:]\n",
    "\n",
    "def mean_reversion_strategy(data, window, position_size=100, transaction_fee_rate=0.00015, slippage_rate=0.00015, k1=1.0, k2=1.0):\n",
    "    mean_spread = data.rolling(window).mean()\n",
    "    std_spread = data.rolling(window).std()\n",
    "    position, entry_spread, cumulative_pnl, pnl_list = 0, 0, 0, []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        current_spread = data.iloc[i]\n",
    "        upper_entry_threshold = mean_spread.iloc[i] + k1 * std_spread.iloc[i]\n",
    "        lower_entry_threshold = mean_spread.iloc[i] - k2 * std_spread.iloc[i]\n",
    "        upper_exit_threshold = mean_spread.iloc[i]\n",
    "        lower_exit_threshold = mean_spread.iloc[i]\n",
    "\n",
    "        if position == 0:\n",
    "            if current_spread > upper_entry_threshold:\n",
    "                position = -1\n",
    "                entry_spread = current_spread\n",
    "            elif current_spread < lower_entry_threshold:\n",
    "                position = 1\n",
    "                entry_spread = current_spread\n",
    "        elif position == 1 and current_spread > lower_exit_threshold:\n",
    "            pnl = (current_spread - entry_spread) * position_size\n",
    "            transaction_cost = (transaction_fee_rate + slippage_rate) * (entry_spread + current_spread)\n",
    "            pnl -= transaction_cost\n",
    "            cumulative_pnl += pnl\n",
    "            pnl_list.append(pnl)\n",
    "            position = 0\n",
    "        elif position == -1 and current_spread < upper_exit_threshold:\n",
    "            pnl = (entry_spread - current_spread) * position_size\n",
    "            transaction_cost = (transaction_fee_rate + slippage_rate) * (entry_spread + current_spread)\n",
    "            pnl -= transaction_cost\n",
    "            cumulative_pnl += pnl\n",
    "            pnl_list.append(pnl)\n",
    "            position = 0\n",
    "\n",
    "    if position != 0:\n",
    "        unrealized_pnl = (current_spread - entry_spread) * position_size if position == 1 else (entry_spread - current_spread) * position_size\n",
    "        cumulative_pnl += unrealized_pnl\n",
    "        pnl_list.append(unrealized_pnl)\n",
    "\n",
    "    return cumulative_pnl, pnl_list\n",
    "\n",
    "windows = {\"15min\": 3, \"20 min\": 4, \"30 min\": 6, \"45 min\": 9, \"1hr\": 12, \"3hr\": 36, \"6hr\": 72, \"12hr\": 144, \"1day\": 288, \"1week\": 2016}\n",
    "results = []\n",
    "\n",
    "for i, col1 in enumerate(cdf_df.columns):\n",
    "    for j, col2 in enumerate(cdf_df.columns):\n",
    "        if i >= j:\n",
    "            continue\n",
    "\n",
    "        pair_data = train_data[[col1, col2]].dropna()\n",
    "        time_start = time.time()\n",
    "\n",
    "        best_window, best_pnl, best_window_name = None, -np.inf, \"\"\n",
    "\n",
    "        for window_name, window in windows.items():\n",
    "            y, X = pair_data[col1], add_constant(pair_data[col2])\n",
    "            rolling_model = RollingOLS(y, X, window=window).fit()\n",
    "            spread = y - (rolling_model.params['const'] + rolling_model.params[col2] * X[col2])\n",
    "            total_pnl, _ = mean_reversion_strategy(spread, window)\n",
    "\n",
    "            if total_pnl > best_pnl:\n",
    "                best_pnl = total_pnl\n",
    "                best_window = window\n",
    "                best_window_name = window_name\n",
    "\n",
    "        time_taken = time.time() - time_start\n",
    "        results.append((f\"{col1}-{col2}\", time_taken, best_pnl, best_window_name))\n",
    "        print(f\"PAIR {col1}-{col2}, TIME TAKEN - {time_taken:.2f}s, TOTAL PNL - {best_pnl:.2f}, BEST WINDOW - {best_window_name}\")\n",
    "\n",
    "top_20_pairs = sorted(results, key=lambda x: x[2], reverse=True)[:20]\n",
    "\n",
    "top_20_cointegration_results = [\n",
    "    (pair[0], coint(train_data[pair[0].split('-')[0]], train_data[pair[0].split('-')[1]])[1], pair[2], pair[3])\n",
    "    for pair in top_20_pairs\n",
    "]\n",
    "\n",
    "print(\"\\nTop 20 Pairs:\")\n",
    "for pair in top_20_cointegration_results:\n",
    "    pair_name, cointegration_pval, best_pnl, best_window_name = pair\n",
    "    print(f\"PAIR: {pair_name}, PNL: {best_pnl:.2f}, COINTEGRATION P-VALUE: {cointegration_pval:.4f}, BEST WINDOW: {best_window_name}\")\n",
    "\n",
    "quantile_data = cdf_df\n",
    "\n",
    "copulas = {\n",
    "    'Gaussian': GaussianMultivariate,\n",
    "    't-Copula': StudentTUnivariate,\n",
    "    'Clayton': Clayton,\n",
    "    'Gumbel': Gumbel,\n",
    "    'Frank': Frank\n",
    "}\n",
    "\n",
    "fit_results = []\n",
    "\n",
    "for i, col1 in enumerate(quantile_data.columns):\n",
    "    for j, col2 in enumerate(quantile_data.columns):\n",
    "        if i >= j:\n",
    "            continue\n",
    "\n",
    "        pair_data = quantile_data[[col1, col2]].dropna().values\n",
    "\n",
    "        best_copula, best_aic, best_params = None, float('inf'), None\n",
    "\n",
    "        for copula_name, CopulaClass in copulas.items():\n",
    "            try:\n",
    "                copula = CopulaClass()\n",
    "                copula.fit(pair_data)\n",
    "                log_likelihood = copula.log_likelihood(pair_data)\n",
    "                num_params = len(copula.to_dict()['theta'])\n",
    "                aic = 2 * num_params - 2 * log_likelihood\n",
    "\n",
    "                if aic < best_aic:\n",
    "                    best_aic = aic\n",
    "                    best_copula = copula_name\n",
    "                    best_params = copula.to_dict()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to fit {copula_name} for pair {col1}-{col2}: {e}\")\n",
    "\n",
    "        fit_results.append({\n",
    "            'pair': f\"{col1}-{col2}\",\n",
    "            'copula': best_copula,\n",
    "            'aic': best_aic,\n",
    "            'params': best_params\n",
    "        })\n",
    "\n",
    "sorted_results = sorted(fit_results, key=lambda x: x['aic'])\n",
    "top_5_pairs = sorted_results[:5]\n",
    "\n",
    "print(\"Top 5 Fitted Copula Pairs:\")\n",
    "for result in top_5_pairs:\n",
    "    print(f\"Pair: {result['pair']}, Copula: {result['copula']}, AIC: {result['aic']}, Params: {result['params']}\")\n",
    "\n",
    "print(\"\\nTrading Strategy Based on Conditional Probabilities:\")\n",
    "def trading_strategy_with_copula(pair_data, copula_params, copula_class, threshold=0.05):\n",
    "    copula = copula_class()\n",
    "    copula.from_dict(copula_params)\n",
    "\n",
    "    trades = []\n",
    "    for u1, u2 in pair_data:\n",
    "        cond_prob_1 = copula.conditional_probability([u1, u2], given=1)\n",
    "        cond_prob_2 = copula.conditional_probability([u1, u2], given=0)\n",
    "\n",
    "        if cond_prob_1 <= threshold and cond_prob_2 >= 1 - threshold:\n",
    "            trades.append(\"Long Spread\")\n",
    "        elif cond_prob_2 <= threshold and cond_prob_1 >= 1 - threshold:\n",
    "            trades.append(\"Short Spread\")\n",
    "        else:\n",
    "            trades.append(\"Exit\")\n",
    "\n",
    "    return trades\n",
    "\n",
    "for result in top_5_pairs:\n",
    "    pair = result['pair']\n",
    "    copula_name = result['copula']\n",
    "    params = result['params']\n",
    "    pair_columns = pair.split('-')\n",
    "    pair_data = quantile_data[pair_columns].dropna().values\n",
    "    trades = trading_strategy_with_copula(pair_data, params, copulas[copula_name])\n",
    "\n",
    "    print(f\"Pair: {pair}, Trades: {trades}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc3b2383-0ca8-4b68-86e7-2ec0607ba6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa0acf4-6680-4ca5-aa19-a2bd38fbe083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
